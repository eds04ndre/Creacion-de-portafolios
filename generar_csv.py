"""
Script para descargar datos histÃ³ricos de ETFs y guardarlos en CSV
Ejecuta este script ANTES de correr la aplicaciÃ³n Streamlit

Instala yfinance primero: pip install yfinance
"""

import yfinance as yf
import pandas as pd
import numpy as np

# ETFs de la estrategia 1: REGIONES
tickers_regiones = ["SPLG", "EWC", "IEUR", "EEM", "EWJ"]

# ETFs de la estrategia 2: SECTORES DE ESTADOS UNIDOS
tickers_sectores = ["XLC", "XLY", "XLP", "XLE", "XLF",
                    "XLV", "XLI", "XLB", "XLRE", "XLK", "XLU"]

print("=" * 70)
print("DESCARGANDO DATOS HISTÃ“RICOS DE ETFs")
print("=" * 70)

print("\nğŸ“Š Descargando datos de ETFs de REGIONES...")
print(f"Tickers: {', '.join(tickers_regiones)}")

# Descargar precios ajustados de los Ãºltimos 4 aÃ±os
data_regiones = yf.download(tickers_regiones, period="4y", progress=True)["Close"]

# Verificar si hay columnas con datos faltantes
print("\nğŸ” Verificando calidad de datos REGIONES:")
for ticker in tickers_regiones:
    if ticker in data_regiones.columns:
        null_count = data_regiones[ticker].isnull().sum()
        total_count = len(data_regiones)
        pct_null = (null_count / total_count) * 100
        
        if pct_null > 50:
            print(f"   âš ï¸  {ticker}: {pct_null:.1f}% datos faltantes ({null_count}/{total_count})")
        elif pct_null > 0:
            print(f"   âš¡ {ticker}: {pct_null:.1f}% datos faltantes ({null_count}/{total_count}) - Interpolando...")
            # Interpolar valores faltantes
            data_regiones[ticker] = data_regiones[ticker].interpolate(method='linear')
        else:
            print(f"   âœ… {ticker}: OK")
    else:
        print(f"   âŒ {ticker}: NO DESCARGADO")

# Si EWC tiene muchos problemas, intentar descargarlo individualmente
if 'EWC' in data_regiones.columns and data_regiones['EWC'].isnull().sum() > len(data_regiones) * 0.5:
    print("\nğŸ”„ Intentando descargar EWC individualmente con perÃ­odo mÃ¡s largo...")
    try:
        ewc_data = yf.download("EWC", period="5y", progress=False)["Close"]
        # Alinear con las fechas de data_regiones
        data_regiones['EWC'] = ewc_data.reindex(data_regiones.index).interpolate(method='linear')
        print(f"   âœ… EWC descargado: {data_regiones['EWC'].isnull().sum()} nulls restantes")
    except Exception as e:
        print(f"   âŒ Error descargando EWC: {e}")

print("\nğŸ“Š Descargando datos de ETFs de SECTORES...")
print(f"Tickers: {', '.join(tickers_sectores)}")

data_sectores = yf.download(tickers_sectores, period="4y", progress=True)["Close"]

# Verificar calidad de datos de sectores
print("\nğŸ” Verificando calidad de datos SECTORES:")
for ticker in tickers_sectores:
    if ticker in data_sectores.columns:
        null_count = data_sectores[ticker].isnull().sum()
        total_count = len(data_sectores)
        pct_null = (null_count / total_count) * 100
        
        if pct_null > 50:
            print(f"   âš ï¸  {ticker}: {pct_null:.1f}% datos faltantes ({null_count}/{total_count})")
        elif pct_null > 0:
            print(f"   âš¡ {ticker}: {pct_null:.1f}% datos faltantes - Interpolando...")
            data_sectores[ticker] = data_sectores[ticker].interpolate(method='linear')
        else:
            print(f"   âœ… {ticker}: OK")
    else:
        print(f"   âŒ {ticker}: NO DESCARGADO")

# Eliminar filas donde TODOS los valores son NaN
data_regiones = data_regiones.dropna(how='all')
data_sectores = data_sectores.dropna(how='all')

# Forward fill para cualquier NaN restante al inicio
data_regiones = data_regiones.fillna(method='ffill').fillna(method='bfill')
data_sectores = data_sectores.fillna(method='ffill').fillna(method='bfill')

# Guardar en CSV
print("\nğŸ’¾ Guardando archivos CSV...")
data_regiones.to_csv('data_regiones.csv')
data_sectores.to_csv('data_sectores.csv')

print("\n" + "=" * 70)
print("âœ… ARCHIVOS GENERADOS EXITOSAMENTE")
print("=" * 70)
print(f"\nğŸ“ data_regiones.csv")
print(f"   - Filas: {len(data_regiones)} dÃ­as")
print(f"   - Columnas: {len(data_regiones.columns)} ETFs")
print(f"   - Rango: {data_regiones.index.min().date()} â†’ {data_regiones.index.max().date()}")
print(f"   - Tickers: {', '.join(data_regiones.columns)}")

print(f"\nğŸ“ data_sectores.csv")
print(f"   - Filas: {len(data_sectores)} dÃ­as")
print(f"   - Columnas: {len(data_sectores.columns)} ETFs")
print(f"   - Rango: {data_sectores.index.min().date()} â†’ {data_sectores.index.max().date()}")
print(f"   - Tickers: {', '.join(data_sectores.columns)}")

# VerificaciÃ³n final de nulls
print("\nğŸ” VERIFICACIÃ“N FINAL DE DATOS FALTANTES:")
nulls_regiones = data_regiones.isnull().sum().sum()
nulls_sectores = data_sectores.isnull().sum().sum()

if nulls_regiones == 0 and nulls_sectores == 0:
    print("   âœ… No hay datos faltantes en ningÃºn archivo")
else:
    if nulls_regiones > 0:
        print(f"   âš ï¸  data_regiones.csv tiene {nulls_regiones} valores faltantes")
    if nulls_sectores > 0:
        print(f"   âš ï¸  data_sectores.csv tiene {nulls_sectores} valores faltantes")

print("\nğŸš€ Ahora puedes ejecutar la aplicaciÃ³n Streamlit:")
print("   streamlit run app.py")
print("=" * 70)